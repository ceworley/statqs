```{r,data,generation,echo=FALSE,results="hide"}
while(T){
  n = sample(8:20,1)
  i = 1:n
  p = runif(1,0.05,0.95)
  w = sample(c(0,1),n,T)
  phat = mean(w)
  devs = w-phat
  sdevs = devs^2
  var = mean(sdevs)
  if(sum(w)>1 & sum(w)<(n-1) & round(phat,3)==phat & phat!=0.5){
    break
  }
}

mydf = data.frame(i,w,devs,sdevs)
colnames(mydf) = c("$$i$$","$$\\mathbf{w}$$","deviations = $\\mathbf{w}-\\hat{p}$","SqrDev = $(\\mathbf{w}-\\hat{p})^2$")
```


Question
========

A sample was gathered. 

$$\mathbf{w} = `r paste(lapply(w,function(w) sprintf("%d",w)),collapse=", ")` $$


```{r echo=F}
write.csv(data.frame(i,w),file="get_VAR.csv", quote = FALSE, row.names = FALSE)
```

You can download the data as a [CSV file](get_VAR.csv).

Determine the variance of the sample.  You can round your final answer to the hundredths place.


Solution
========

(ANS=`r var`)

[video](https://vimeo.com/531911277){target="_blank"}

First, determine the mean of the sample. Remember, if a sample is all 0s and 1s, then the sample's mean is the same as the sample proportion ($\hat{p}$). 

$$\hat{p} = \bar{w} = \frac{\sum \mathbf{w}}{n} =`r mean(w)` $$

Determine the squared deviations (squared distances from $\hat{p}$).

<style type="text/css" rel="stylesheet">
.bordered-table {
    border-collapse: collapse;
    border-spacing: 0;
    border:2px solid #000000;
}
.bordered-table th {
    border:2px solid #000000;
    padding: 4px;
}
.bordered-table td{
    border:2px solid #000000;
    padding: 4px;
}
</style>

```{r tab1, results="asis", echo=F}
knitr::kable(mydf,format="html",table.attr='class="bordered-table"', align = "cccc",row.names=F)
```


Now, take the mean of the squared deviations to determine the variance.

$$\text{VAR} = \frac{\sum\limits_{i=1}^n (w_i-\bar{w})^2}{n} = \frac{\sum\limits_{i=1}^n (w_i-\hat{p{}})^2}{n} = `r var` $$

### IMPORTANT NOTE (notation and central limit theorem):

I will usually use $\mathbf{w}$ (not conventional) to represent raw data of 0s and 1s (instead of $\mathbf{x}$), because in the context of 0s and 1s, $x_i$ usually implies the number of successes in $n$ trials. 
$$x_i= \sum_{j=1}^{n} w_{i,j}$$
When $x_i$ represents a count of successes in $n$ ([independent](https://en.wikipedia.org/wiki/Independence_(probability_theory))) trials, a large sample of counts ($\mathbf{x}$) follows a [binomial distribution](https://en.wikipedia.org/wiki/Binomial_distribution), which is a special case of more general [distributions of sums or means](https://en.wikipedia.org/wiki/Central_limit_theorem), which tend to be [normally distributed](https://en.wikipedia.org/wiki/Normal_distribution).

The [Central Limit Theorem](https://en.wikipedia.org/wiki/Central_limit_theorem) states that random averages (means) and random sums follow normal probability distributions. The expected value and standard deviation of the [sampling distribution](https://en.wikipedia.org/wiki/Sampling_distribution) is either calculated from the underlying distribution's parameters or guessed from a sample's statistics.

Notice, when dealing with [binomial distributions](https://en.wikipedia.org/wiki/Binomial_distribution), the underlying [Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution) is rarely discussed, and even when it is, "$w$" is not used. So, this notation is not conventional. The conventional notation for $\bar{w}$ is $\hat{p}$, where the hat denotes "estimated", because sample proportion $\hat{p}$ is an estimate of the underlying population proportion $p$.

### spreadsheet

```{r echo=F}
phat = mean(w)
sol = data.frame(i,w)

sol = rbind(sol,
            c("",""),
            c("","phat"),
            c("",paste0("=average(B2:B",n+1,")",collapse="")),
            c("","")
            )

deviations = c(paste0("=B",2:(n+1),"-B$",n+4),rep("",4))
sqrdev = c(paste0("=C",2:(n+1),"^2"),
           "",
           "VAR",
           paste0("=average(D2:D",n+1,")"),
           paste0("=VAR.P(B2:B",n+1,")"))
sol = cbind(sol,deviations,sqrdev)
write.csv(sol,file="get_VAR_sol.csv", row.names=F)
```

You can do this with [a spreadsheet](get_VAR_sol.csv).

```{r fig.height=6,fig.width=8,echo=F}
draw_ss = function(df){
  nrow = length(df[,1])
  ncol = length(df[1,])
  par(mar=c(0,0,0,0))
  plot(0,0,type="n",xlim=c(0,1),ylim=c(0,1),axes=F,ann=F)
  hi = 1:((nrow+2)*2+1)
  vi = 1:((ncol+1)*2+1)
  hpos = seq(1,0,length.out=(nrow+2)*2+1)
  vpos = seq(0,1,length.out=(ncol+1)*2+1)
  hlin = hpos[hi%%2==1]
  ytex = hpos[hi%%2==0]
  vlin = vpos[vi%%2==1]
  xtex = vpos[vi%%2==0]
  abline(h=hlin)
  abline(h=hlin[2],lwd=3)
  abline(v=vlin)
  abline(v=vlin[2],lwd=3)
  for(i in 2:(ncol+1)){
    text(xtex[i],ytex[1],LETTERS[i-1],col=rgb(0.5,0.5,0.5))
    text(xtex[i],ytex[2],colnames(df)[i-1])
  }    
  for(i in 2:(nrow+2)){
    text(xtex[1],ytex[i],i-1,col=rgb(0.5,0.5,0.5))
  }
  for(i in 1:nrow){
    for(j in 1:ncol){
      text(xtex[j+1],ytex[i+2],df[i,j])
    }
  }
}

draw_ss(sol)
```
\

And, actually, you can skip a lot of work by using the [`VAR.P` function](https://wiki.openoffice.org/wiki/Documentation/How_Tos/Calc:_VARP_function){target="blank"}. Notice, you use the population function even though the data is a sample. This is because, with proportions, the mean and variance are intrinsically linked (not independent). 

In fact, we will see that the sample variance of 0s and 1s can be calculated from the sample proportion.

$$\text{VAR}_{\text{bernoulli}} = \hat{p}(1-\hat{p})$$


### R

You can do this with R

```{r}
w = read.csv("get_VAR.csv")$w
phat = mean(w)
deviations = w-phat
sqrdev = deviations^2
VAR = mean(sqrdev)
w
phat
deviations
sqrdev
VAR
# The built-in var() function almost works, but it is too fancy, and makes a Bessel correction. To use it, we need to undo the Bessel correction.
n = length(w)
var(w)*(n-1)/(n)
```

### Algebra

As mentioned earlier, there is an intrinsic link between $\hat{p}$ (the mean of 0s and 1s) and $s$ (the variance of 0s and 1s).

Let $n_0$ represent the number of 0s and $n_1$ represent the number of ones.
$$\hat{p} = \frac{n_1}{n_0+n_1} $$
We can find a simple formula for variance (when data is 0s and 1s [Bernoulli]).
$$\begin{aligned}\text{VAR}_\text{bern} &= \frac{\sum(\mathbf{w}-\hat{p})^2}{n_0+n_1}\\\\
&= \frac{n_0(\hat{p}-0)^2+n_1(1-\hat{p})^2}{n_0+n_1}\\\\
&= \frac{n_0\left(\frac{n_1}{n_0+n_1}\right)^2+n_1\left(1-\frac{n_1}{n_0+n_1}\right)^2}{n_0+n_1}\\\\
&= \frac{n_0\left(\frac{n_1}{n_0+n_1}\right)^2+n_1\left(\frac{n_0}{n_0+n_1}\right)^2}{n_0+n_1}\\\\
&= \frac{n_0}{n_0+n_1}\cdot\frac{n_1}{n_0+n_1}\\\\
&= \hat{p}(1-\hat{p})
\end{aligned}$$

So, you could have just found $\hat{p}$.
$$\hat{p} = \frac{n_1}{n_0+n_1} = \frac{`r sum(w)`}{`r length(w)`} = `r phat` $$
Then used the formula.
$$\text{VAR}_\text{bern} =\hat{p}(1-\hat{p}) = (`r phat`)(1-`r phat`) = `r var` $$


Meta-information
================
extype: num
exsolution: `r var`
exname: get_VAR_prop
extol: 0.01
exextra[numwidth,character]: 999.999
exextra[stringwidth,numeric]: 20
